{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from model.model import Model\n",
    "from tests.rigid_utils import Rigid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# of_basic_features = torch.load('kilian/basic_features.pt', map_location='cpu')\n",
    "# \n",
    "# extra_msa_feat = torch.load('kilian/extra_msa_feat.pt', map_location='cpu')\n",
    "# msa_feat = of_basic_features['msa_feat']\n",
    "# residue_index = of_basic_features['residue_index']\n",
    "# target_feat = of_basic_features['target_feat']\n",
    "\n",
    "c_z = 128\n",
    "c_m  = 256\n",
    "tf_dim = 21\n",
    "openfold_param_path = ('tests/openfold_params/finetuning_ptm_2.pt')\n",
    "\n",
    "# batch = {'extra_msa_feat': extra_msa_feat, 'msa_feat': msa_feat, 'residue_index': residue_index, 'target_feat': target_feat}\n",
    "batch = torch.load('tests/test_outputs/my_batch.pt', map_location='cuda')\n",
    "batch['target_feat'] = batch['target_feat'][:, 1:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def remap_weight_names(openfold_weights):\n",
    "    name_map = {\n",
    "        'core.msa_transition': 'msa_transition',\n",
    "        'core.outer_product_mean': 'outer_product_mean',\n",
    "        'msa_att_col._msa_att': 'msa_att_col',\n",
    "        'transition.layers.0.linear_1': 'transition.linear_1',\n",
    "        'transition.layers.0.linear_2': 'transition.linear_2',\n",
    "        'transition.layers.0.linear_3': 'transition.linear_3',\n",
    "    }\n",
    "    for key in list(openfold_weights.keys()):\n",
    "        new_key = None\n",
    "        for sub in name_map.keys():\n",
    "            if sub in key:\n",
    "                new_key = key.replace(sub, name_map[sub])\n",
    "        \n",
    "        if 'structure_module.ipa.linear_kv.'in key:\n",
    "            value = openfold_weights[key]\n",
    "            if 'weight' in key:\n",
    "                value = value.T\n",
    "            n_head=12\n",
    "            c=16\n",
    "            value = value.view(value.shape[:-1]+(n_head,2*c))\n",
    "            k, v = value.split(c, dim=-1)\n",
    "            if 'weight' in key:\n",
    "                openfold_weights['structure_module.ipa.linear_k.weight'] = k.flatten(start_dim=-2).T\n",
    "                openfold_weights['structure_module.ipa.linear_v.weight'] = v.flatten(start_dim=-2).T\n",
    "            else:\n",
    "                openfold_weights['structure_module.ipa.linear_k.bias'] = k.flatten(start_dim=-2)\n",
    "                openfold_weights['structure_module.ipa.linear_v.bias'] = v.flatten(start_dim=-2)\n",
    "\n",
    "            openfold_weights.pop(key)\n",
    "\n",
    "        if 'structure_module.ipa.linear_kv_points.' in key:\n",
    "            value=openfold_weights[key]\n",
    "            if 'weight' in key:\n",
    "                value=value.T\n",
    "            n_head=12\n",
    "            query_points=4\n",
    "            value_points=8\n",
    "            value = value.view(value.shape[:-1] + (3*n_head, query_points+value_points))\n",
    "            k, v = value.split([query_points, value_points], dim=-1)\n",
    "            if 'weight' in key:\n",
    "                openfold_weights['structure_module.ipa.linear_k_points.weight'] = k.flatten(start_dim=-2).T\n",
    "                openfold_weights['structure_module.ipa.linear_v_points.weight'] = v.flatten(start_dim=-2).T\n",
    "            else:\n",
    "                openfold_weights['structure_module.ipa.linear_k_points.bias'] = k.flatten(start_dim=-2)\n",
    "                openfold_weights['structure_module.ipa.linear_v_points.bias'] = v.flatten(start_dim=-2)\n",
    "            openfold_weights.pop(key)\n",
    "\n",
    "        if 'structure_module.angle_resnet.linear_out' in key:\n",
    "            value = openfold_weights[key]\n",
    "            swap = value[::2].clone()\n",
    "            value[::2] = value[1::2]\n",
    "            value[1::2] = swap\n",
    "            print(f'Swapping {key}')\n",
    "            openfold_weights[key] = value\n",
    "        \n",
    "        if 'linear_tf' in key and 'weight' in key:\n",
    "            openfold_weights[key] = openfold_weights[key][:, 1:]\n",
    "\n",
    "        \n",
    "        # if 'structure_module.angle_resnet.linear_out.bias' in key:\n",
    "            #value = openfold_weights[key]\n",
    "\n",
    "        if new_key is not None:\n",
    "            openfold_weights[new_key] = openfold_weights.pop(key)\n",
    "\n",
    "# remap_weight_names(openfold_weights)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.utils import load_openfold_weights\n",
    "openfold_weights = load_openfold_weights(openfold_param_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "for key, tensor in batch.items():\n",
    "    batch[key] = tensor.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "model = Model()\n",
    "res = model.load_state_dict(openfold_weights, strict=False)\n",
    "# print(type(res))\n",
    "missing_struct = [a for a in res.missing_keys if 'structure' in a]\n",
    "incompatible = [a for a in res.unexpected_keys if 'template' not in a]\n",
    "\n",
    "for key in incompatible:\n",
    "    if 'template' not in key and 'aux' not in key:\n",
    "        print(key)\n",
    "        print(torch.abs(openfold_weights[key]).mean())\n",
    "\n",
    "\n",
    "model.to('cuda')\n",
    "model.eval()\n",
    "pass\n",
    "# print(next(model.parameters()).device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting iteration 0...\n",
      "Starting iteration 1...\n",
      "Starting iteration 2...\n",
      "Starting iteration 3...\n"
     ]
    }
   ],
   "source": [
    "s = torch.load('tests/test_outputs/s_evo.pt', map_location='cuda')\n",
    "z = torch.load('tests/test_outputs/z_evo.pt', map_location='cuda')\n",
    "F = batch['target_feat'].argmax(dim=-1) - 1\n",
    "F = F.to('cuda')\n",
    "with torch.no_grad():\n",
    "    outputs = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([59, 37, 3])\n"
     ]
    }
   ],
   "source": [
    "my_angles = outputs['angles'][..., -1]\n",
    "my_frames = outputs['frames'][..., -1]\n",
    "my_positions = outputs['final_positions'][..., -1]\n",
    "my_mask = outputs['position_mask'][..., -1]\n",
    "print(my_positions.shape)\n",
    "\n",
    "of_angles = torch.load('tests/test_outputs/final_angles.pt')\n",
    "of_frames = torch.load('tests/test_outputs/final_frames.pt')\n",
    "of_positions = torch.load('tests/test_outputs/final_positions.pt')\n",
    "of_mask = torch.load('tests/test_outputs/final_atom_mask.pt')\n",
    "\n",
    "swap = of_angles[...,::2].clone()\n",
    "of_angles[...,::2] = of_angles[...,1::2]\n",
    "of_angles[...,1::2] = swap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 59, 3, 3]) torch.Size([8, 59, 3])\n"
     ]
    }
   ],
   "source": [
    "rigid = Rigid.from_tensor_7(of_frames)\n",
    "of_rot_mats = rigid.get_rots().get_rot_mats()\n",
    "of_trans = rigid.get_trans()\n",
    "print(of_rot_mats.shape, of_trans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.2970e-07, device='cuda:0')\n",
      "tensor(9.1562e-07, device='cuda:0')\n",
      "tensor(7.1322e-08, device='cuda:0')\n",
      "torch.Size([59, 37, 3]) torch.Size([59, 37])\n",
      "tensor(1.8410e-07, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(torch.abs(of_rot_mats-my_frames[...,:3,:3]).mean())\n",
    "print(torch.abs(of_trans-my_frames[...,:3,3]*10).mean())\n",
    "print(torch.abs(of_angles-my_angles/torch.linalg.vector_norm(my_angles, dim=-1, keepdim=True)).mean())\n",
    "\n",
    "print(my_positions.shape, my_mask.shape)\n",
    "my_positions = my_positions * my_mask.unsqueeze(-1)\n",
    "\n",
    "print((my_positions-of_positions).abs().mean() / of_positions.abs().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import modelcif\n",
    "import modelcif.model\n",
    "import modelcif.dumper\n",
    "import io\n",
    "from geometry.residue_constants import atom_types\n",
    "\n",
    "def to_modelcif(atom_positions, atom_mask, sequence):\n",
    "    atom_positions = atom_positions.numpy()\n",
    "    atom_mask = atom_mask.numpy()\n",
    "    n = atom_positions.shape[0]\n",
    "    system = modelcif.System(title='AlphaFold prediction')\n",
    "    entity = modelcif.Entity(sequence, description='Model subunit')\n",
    "    asym_unit = modelcif.AsymUnit(entity, details='Model subunit A', id='A')\n",
    "    modeled_assembly = modelcif.Assembly([asym_unit], name='Modeled assembly')\n",
    "    class _MyModel(modelcif.model.AbInitioModel):\n",
    "        def get_atoms(self):\n",
    "            for i in range(n):\n",
    "                for atom_name, pos, mask in zip(atom_types, atom_positions[i], atom_mask[i]):\n",
    "                    if not mask:\n",
    "                        continue\n",
    "                    element = atom_name[0]\n",
    "                    yield modelcif.model.Atom(\n",
    "                        asym_unit=asym_unit,\n",
    "                        type_symbol=element,\n",
    "                        seq_id=i+1,\n",
    "                        atom_id=atom_name,\n",
    "                        x=pos[0], y=pos[1], z=pos[2],\n",
    "                        het=False,\n",
    "                        occupancy=1.00\n",
    "                    )\n",
    "\n",
    "    model = _MyModel(assembly=modeled_assembly, name='Model')\n",
    "    model_group = modelcif.model.ModelGroup([model], name='All models')\n",
    "    system.model_groups.append(model_group)\n",
    "    fh = io.StringIO()\n",
    "    modelcif.dumper.write(fh, [system])\n",
    "    return fh.getvalue()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = 'PIAQIHILEGRSDEQKETLIREVSEAISRSLDAPLTSVRVIITEMAKGHFGIGGELASK'\n",
    "with open('./prediction.cif', 'w') as f:\n",
    "    f.write(to_modelcif(my_positions.to('cpu'), my_mask.to('cpu'), sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfold_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
